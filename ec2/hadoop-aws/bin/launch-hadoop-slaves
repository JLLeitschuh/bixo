#!/usr/bin/env bash

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Launch a set of EC2 Hadoop slave instances to do the bidding of
# a previously launched master instance:
# launch-hadooop-slaves <cluster> <#slaves> [<type> [<price>]]

if [ -z $1 ]; then
  echo "Cluster name required!"
  exit -1
fi

if [ -z $2 ]; then
  echo "You must specify the number of slaves to start."
  exit -1
fi

CLUSTER=$1
NUM_SLAVES=$2
INSTANCE_TYPE={$3:-$DEFAULT_INSTANCE_TYPE}
SPOT_PRICE=$4

# Import variables
bin=`dirname "$0"`
bin=`cd "$bin"; pwd`
. ${HADOOP_EC2_ENV:-$bin/hadoop-ec2-env.sh}

if [ ! -f $MASTER_IP_PATH ]; then
  echo "You must launch the cluster's master node first!"
  exit -1
fi

# Find the Hadoop image in the S3 bucket
AMI_IMAGE=`ec2-describe-images -a | grep $S3_BUCKET | grep $HADOOP_VERSION | grep $ARCH${HADOOP_EC2_PROFILE:+-$HADOOP_EC2_PROFILE} | grep available | awk '{print $2}'`

# Retrieve cluster description from user's home directory where launch-hadoop-master
# has saved it.
MASTER_HOST=`cat $MASTER_PRIVATE_IP_PATH`
MASTER_ZONE=`cat $MASTER_ZONE_PATH`

# Resolve several variable values within hadoop-ec2-init-remote.sh, to create a script
# that will be installed on the slaves and executed there during the boot sequence.
sed -e "s|%MASTER_HOST%|$MASTER_HOST|" \
    -e "s|%AWS_ACCESS_KEY_ID%|$AWS_ACCESS_KEY_ID|" \
    -e "s|%AWS_SECRET_ACCESS_KEY%|$AWS_SECRET_ACCESS_KEY|" \
    -e "s|%INSTANCE_TYPE%|$INSTANCE_TYPE|" \
    -e "s|%EXTRA_CORE_SITE_PROPERTIES%|$EXTRA_CORE_SITE_PROPERTIES|" \
    -e "s|%EXTRA_HDFS_SITE_PROPERTIES%|$EXTRA_HDFS_SITE_PROPERTIES|" \
    -e "s|%EXTRA_MAPRED_SITE_PROPERTIES%|$EXTRA_MAPRED_SITE_PROPERTIES|" \
       "$USER_DATA_FILE_TEMPLATE" > .user_data_file.slave

# Launch all the slave instances
if [ -z $SPOT_PRICE ]; then
    echo "Adding $NUM_SLAVES node(s) to cluster group $CLUSTER with AMI $AMI_IMAGE"
    ec2-run-instances $AMI_IMAGE -n "$NUM_SLAVES" -g "$CLUSTER" -k "$KEY_NAME" -f .user_data_file.slave -t "$INSTANCE_TYPE" -z "$MASTER_ZONE" $KERNEL_ARG | grep INSTANCE | awk '{print $2}'
else
    echo "Requesting $NUM_SLAVES (max price $SPOT_PRICE) spot instance node(s) for cluster group $CLUSTER with AMI $AMI_IMAGE"
    ec2-request-spot-instances $AMI_IMAGE \
        --price "$SPOT_PRICE" \
        --instance-count "$NUM_SLAVES" \
        --launch-group "$CLUSTER" \
        --group "$CLUSTER" \
        -k "$KEY_NAME" \
        --user-data-file .user_data_file.slave \
        --instance-type "$INSTANCE_TYPE" \
        --availability-zone-group "$MASTER_ZONE" \
        $KERNEL_ARG \
        | grep SPOTINSTANCEREQUEST | awk '{print $2}'
fi
rm .user_data_file.slave
